{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, *args, **kwargs):\n",
    "        return x\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load data\n",
    "data = np.load('data_with_labels.npz')\n",
    "train = data['arr_0']/255.\n",
    "labels = data['arr_1']\n",
    "\n",
    "# Look at some data\n",
    "print(train[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you have matplotlib installed\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "def to_onehot(labels,nclasses = 5):\n",
    "    '''\n",
    "    Convert labels to \"one-hot\" format.\n",
    "    >>> a = [0,1,2,3]\n",
    "    >>> to_onehot(a,5)\n",
    "    array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "           [ 0.,  1.,  0.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  0.,  0.,  1.,  0.]])\n",
    "    '''\n",
    "    outlabels = np.zeros((len(labels),nclasses))\n",
    "    for i,l in enumerate(labels):\n",
    "        outlabels[i,l] = 1\n",
    "    return outlabels\n",
    "\n",
    "onehot = to_onehot(labels)\n",
    "\n",
    "# Split data into training and validation\n",
    "indices = np.random.permutation(train.shape[0])\n",
    "valid_cnt = int(train.shape[0] * 0.1)\n",
    "test_idx, training_idx = indices[:valid_cnt],\\\n",
    "                         indices[valid_cnt:]\n",
    "test, train = train[test_idx,:],\\\n",
    "              train[training_idx,:]\n",
    "onehot_test, onehot_train = onehot[test_idx,:],\\\n",
    "                        onehot[training_idx,:]\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# These will be inputs\n",
    "## Input pixels, image with one channel (gray)\n",
    "x = tf.placeholder(\"float\", [None, 36, 36])\n",
    "# Note that -1 is for reshaping\n",
    "x_im = tf.reshape(x, [-1,36,36,1])\n",
    "## Known labels\n",
    "# None works during variable creation to be\n",
    "# unspecified size\n",
    "y_ = tf.placeholder(\"float\", [None,5])\n",
    "\n",
    "# Conv layer 1\n",
    "num_filters1 = 16\n",
    "winx1 = 3\n",
    "winy1 = 3\n",
    "W1 = tf.Variable(tf.truncated_normal(\n",
    "    [winx1, winy1, 1 , num_filters1],\n",
    "    stddev=1./math.sqrt(winx1*winy1)))\n",
    "b1 = tf.Variable(tf.constant(0.1,\n",
    "                shape=[num_filters1]))\n",
    "# 5x5 convolution, pad with zeros on edges\n",
    "xw = tf.nn.conv2d(x_im, W1,\n",
    "                  strides=[1, 1, 1, 1],\n",
    "                  padding='SAME')\n",
    "h1 = tf.nn.relu(xw + b1)\n",
    "# 2x2 Max pooling, no padding on edges\n",
    "p1 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],\n",
    "        strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Conv layer 2\n",
    "num_filters2 = 4\n",
    "winx2 = 3\n",
    "winy2 = 3\n",
    "W2 = tf.Variable(tf.truncated_normal(\n",
    "    [winx2, winy2, num_filters1, num_filters2],\n",
    "    stddev=1./math.sqrt(winx2*winy2)))\n",
    "b2 = tf.Variable(tf.constant(0.1,\n",
    "     shape=[num_filters2]))\n",
    "# 3x3 convolution, pad with zeros on edges\n",
    "p1w2 = tf.nn.conv2d(p1, W2,\n",
    "       strides=[1, 1, 1, 1], padding='SAME')\n",
    "h1 = tf.nn.relu(p1w2 + b2)\n",
    "# 2x2 Max pooling, no padding on edges\n",
    "p2 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],\n",
    "     strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Need to flatten convolutional output\n",
    "p2_size = np.product(\n",
    "        [s.value for s in p2.get_shape()[1:]])\n",
    "p2f = tf.reshape(p2, [-1, p2_size ])\n",
    "\n",
    "# Dense layer\n",
    "num_hidden = 32\n",
    "W3 = tf.Variable(tf.truncated_normal(\n",
    "     [p2_size, num_hidden],\n",
    "     stddev=2./math.sqrt(p2_size)))\n",
    "b3 = tf.Variable(tf.constant(0.2,\n",
    "     shape=[num_hidden]))\n",
    "h3 = tf.nn.relu(tf.matmul(p2f,W3) + b3)\n",
    "\n",
    "# Drop out training\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h3_drop = tf.nn.dropout(h3, keep_prob)\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.truncated_normal(\n",
    "     [num_hidden, 5],\n",
    "     stddev=1./math.sqrt(num_hidden)))\n",
    "b4 = tf.Variable(tf.constant(0.1,shape=[5]))\n",
    "\n",
    "# Just initialize\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Define model\n",
    "y = tf.nn.softmax(tf.matmul(h3_drop,W4) + b4)\n",
    "\n",
    "### End model specification, begin training code\n",
    "\n",
    "\n",
    "# Climb on cross-entropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "        y + 1e-50, y_))\n",
    "\n",
    "# How we train\n",
    "train_step = tf.train.GradientDescentOptimizer(\n",
    "             0.01).minimize(cross_entropy)\n",
    "\n",
    "# Define accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),\n",
    "                              tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(\n",
    "           correct_prediction, \"float\"))\n",
    "\n",
    "# Actually train\n",
    "epochs = 3000\n",
    "train_acc = np.zeros(epochs//10)\n",
    "test_acc = np.zeros(epochs//10)\n",
    "for i in tqdm(range(epochs), ascii=True):\n",
    "    # Record summary data, and the accuracy\n",
    "    if i % 10 == 0:  \n",
    "        # Check accuracy on train set\n",
    "        A = accuracy.eval(feed_dict={x: train,\n",
    "            y_: onehot_train, keep_prob: 1.0})\n",
    "        train_acc[i//10] = A\n",
    "        # And now the validation set\n",
    "        A = accuracy.eval(feed_dict={x: test,\n",
    "            y_: onehot_test, keep_prob: 1.0})\n",
    "        test_acc[i//10] = A\n",
    "    train_step.run(feed_dict={x: train,\\\n",
    "        y_: onehot_train, keep_prob: 0.5})\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(train_acc,'bo')\n",
    "plt.plot(test_acc,'rx')\n",
    "\n",
    "# Look at the final testing confusion matrix\n",
    "pred = np.argmax(y.eval(\n",
    "       feed_dict={x: test, keep_prob: 1.0,\n",
    "       y_: onehot_test}), axis = 1)\n",
    "conf = np.zeros([5,5])\n",
    "for p,t in zip(pred,np.argmax(onehot_test,\n",
    "                              axis=1)):\n",
    "    conf[t,p] += 1\n",
    "\n",
    "plt.matshow(conf)\n",
    "plt.colorbar()\n",
    "\n",
    "# Let's look at a subplot of some weights\n",
    "f, plts = plt.subplots(4,4)\n",
    "for i in range(16):\n",
    "    plts[i//4,i%4].matshow(W1.eval()[:,:,0,i],\n",
    "            cmap = plt.cm.gray_r)\n",
    "\n",
    "# Examine the output weights\n",
    "plt.matshow(W4.eval().T)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"conv2a.ckpt\")\n",
    "\n",
    "# Restore\n",
    "saver.restore(sess, \"conv2a.ckpt\")\n",
    "\n",
    "# Or use Numpy manually\n",
    "def save_all(name = 'conv2'):\n",
    "    np.savez_compressed(name, W1.eval(),\n",
    "            b1.eval(), W2.eval(), b2.eval(),\n",
    "            W3.eval(), b3.eval(), W4.eval(),\n",
    "            b4.eval())\n",
    "\n",
    "save_all()\n",
    "\n",
    "def load_all(name = 'conv2.npz'):\n",
    "    data = np.load(name)\n",
    "    sess.run(W1.assign(data['arr_0']))\n",
    "    sess.run(b1.assign(data['arr_1']))\n",
    "    sess.run(W2.assign(data['arr_2']))\n",
    "    sess.run(b2.assign(data['arr_3']))\n",
    "    sess.run(W3.assign(data['arr_4']))\n",
    "    sess.run(b3.assign(data['arr_5']))\n",
    "    sess.run(W4.assign(data['arr_6']))\n",
    "    sess.run(b4.assign(data['arr_7']))\n",
    "\n",
    "load_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
