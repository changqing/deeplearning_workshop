{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Intel(R) Core(TM) i3-6100 CPU @ 3.70GHz  4 kernel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, *args, **kwargs):\n",
    "        return x\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load data\n",
    "data = np.load('data_with_labels.npz')\n",
    "train = data['arr_0']/255.\n",
    "labels = data['arr_1']\n",
    "\n",
    "# Look at some data\n",
    "print(train[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "epoch:  20\n",
      "epoch:  21\n",
      "epoch:  22\n",
      "epoch:  23\n",
      "epoch:  24\n",
      "epoch:  25\n",
      "epoch:  26\n",
      "epoch:  27\n",
      "epoch:  28\n",
      "epoch:  29\n",
      "epoch:  30\n",
      "epoch:  31\n",
      "epoch:  32\n",
      "epoch:  33\n",
      "epoch:  34\n",
      "epoch:  35\n",
      "epoch:  36\n",
      "epoch:  37\n",
      "epoch:  38\n",
      "epoch:  39\n",
      "epoch:  40\n",
      "epoch:  41\n",
      "epoch:  42\n",
      "epoch:  43\n",
      "epoch:  44\n",
      "epoch:  45\n",
      "epoch:  46\n",
      "epoch:  47\n",
      "epoch:  48\n",
      "epoch:  49\n",
      "epoch:  50\n",
      "epoch:  51\n",
      "epoch:  52\n",
      "epoch:  53\n",
      "epoch:  54\n",
      "epoch:  55\n",
      "epoch:  56\n",
      "epoch:  57\n",
      "epoch:  58\n",
      "epoch:  59\n",
      "epoch:  60\n",
      "epoch:  61\n",
      "epoch:  62\n",
      "epoch:  63\n",
      "epoch:  64\n",
      "epoch:  65\n",
      "epoch:  66\n",
      "epoch:  67\n",
      "epoch:  68\n",
      "epoch:  69\n",
      "epoch:  70\n",
      "epoch:  71\n",
      "epoch:  72\n",
      "epoch:  73\n",
      "epoch:  74\n",
      "epoch:  75\n",
      "epoch:  76\n",
      "epoch:  77\n",
      "epoch:  78\n",
      "epoch:  79\n",
      "epoch:  80\n",
      "epoch:  81\n",
      "epoch:  82\n",
      "epoch:  83\n",
      "epoch:  84\n",
      "epoch:  85\n",
      "epoch:  86\n",
      "epoch:  87\n",
      "epoch:  88\n",
      "epoch:  89\n",
      "epoch:  90\n",
      "epoch:  91\n",
      "epoch:  92\n",
      "epoch:  93\n",
      "epoch:  94\n",
      "epoch:  95\n",
      "epoch:  96\n",
      "epoch:  97\n",
      "epoch:  98\n",
      "epoch:  99\n",
      "epoch:  100\n",
      "epoch:  101\n",
      "epoch:  102\n",
      "epoch:  103\n",
      "epoch:  104\n",
      "epoch:  105\n",
      "epoch:  106\n",
      "epoch:  107\n",
      "epoch:  108\n",
      "epoch:  109\n",
      "epoch:  110\n",
      "epoch:  111\n",
      "epoch:  112\n",
      "epoch:  113\n",
      "epoch:  114\n",
      "epoch:  115\n",
      "epoch:  116\n",
      "epoch:  117\n",
      "epoch:  118\n",
      "epoch:  119\n",
      "epoch:  120\n",
      "epoch:  121\n",
      "epoch:  122\n",
      "epoch:  123\n",
      "epoch:  124\n",
      "epoch:  125\n",
      "epoch:  126\n",
      "epoch:  127\n",
      "epoch:  128\n",
      "epoch:  129\n",
      "epoch:  130\n",
      "epoch:  131\n",
      "epoch:  132\n",
      "epoch:  133\n",
      "epoch:  134\n",
      "epoch:  135\n",
      "epoch:  136\n",
      "epoch:  137\n",
      "epoch:  138\n",
      "epoch:  139\n",
      "epoch:  140\n",
      "epoch:  141\n",
      "epoch:  142\n",
      "epoch:  143\n",
      "epoch:  144\n",
      "epoch:  145\n",
      "epoch:  146\n",
      "epoch:  147\n",
      "epoch:  148\n",
      "epoch:  149\n",
      "epoch:  150\n",
      "epoch:  151\n",
      "epoch:  152\n",
      "epoch:  153\n",
      "epoch:  154\n",
      "epoch:  155\n",
      "epoch:  156\n",
      "epoch:  157\n",
      "epoch:  158\n",
      "epoch:  159\n",
      "epoch:  160\n",
      "epoch:  161\n",
      "epoch:  162\n",
      "epoch:  163\n",
      "epoch:  164\n",
      "epoch:  165\n",
      "epoch:  166\n",
      "epoch:  167\n",
      "epoch:  168\n",
      "epoch:  169\n",
      "epoch:  170\n",
      "epoch:  171\n",
      "epoch:  172\n",
      "epoch:  173\n",
      "epoch:  174\n",
      "epoch:  175\n",
      "epoch:  176\n",
      "epoch:  177\n",
      "epoch:  178\n",
      "epoch:  179\n",
      "epoch:  180\n",
      "epoch:  181\n",
      "epoch:  182\n",
      "epoch:  183\n",
      "epoch:  184\n",
      "epoch:  185\n",
      "epoch:  186\n",
      "epoch:  187\n",
      "epoch:  188\n",
      "epoch:  189\n",
      "epoch:  190\n",
      "epoch:  191\n",
      "epoch:  192\n",
      "epoch:  193\n",
      "epoch:  194\n",
      "epoch:  195\n",
      "epoch:  196\n",
      "epoch:  197\n",
      "epoch:  198\n",
      "epoch:  199\n",
      "epoch:  200\n",
      "epoch:  201\n",
      "epoch:  202\n",
      "epoch:  203\n",
      "epoch:  204\n",
      "epoch:  205\n",
      "epoch:  206\n",
      "epoch:  207\n",
      "epoch:  208\n",
      "epoch:  209\n",
      "epoch:  210\n",
      "epoch:  211\n",
      "epoch:  212\n",
      "epoch:  213\n",
      "epoch:  214\n",
      "epoch:  215\n",
      "epoch:  216\n",
      "epoch:  217\n",
      "epoch:  218\n",
      "epoch:  219\n",
      "epoch:  220\n",
      "epoch:  221\n",
      "epoch:  222\n",
      "epoch:  223\n",
      "epoch:  224\n",
      "epoch:  225\n",
      "epoch:  226\n",
      "epoch:  227\n",
      "epoch:  228\n",
      "epoch:  229\n",
      "epoch:  230\n",
      "epoch:  231\n",
      "epoch:  232\n",
      "epoch:  233\n",
      "epoch:  234\n",
      "epoch:  235\n",
      "epoch:  236\n",
      "epoch:  237\n",
      "epoch:  238\n",
      "epoch:  239\n",
      "epoch:  240\n",
      "epoch:  241\n",
      "epoch:  242\n",
      "epoch:  243\n",
      "epoch:  244\n",
      "epoch:  245\n",
      "epoch:  246\n",
      "epoch:  247\n",
      "epoch:  248\n",
      "epoch:  249\n",
      "epoch:  250\n",
      "epoch:  251\n",
      "epoch:  252\n",
      "epoch:  253\n",
      "epoch:  254\n",
      "epoch:  255\n",
      "epoch:  256\n",
      "epoch:  257\n",
      "epoch:  258\n",
      "epoch:  259\n",
      "epoch:  260\n",
      "epoch:  261\n",
      "epoch:  262\n",
      "epoch:  263\n",
      "epoch:  264\n",
      "epoch:  265\n",
      "epoch:  266\n",
      "epoch:  267\n",
      "epoch:  268\n",
      "epoch:  269\n",
      "epoch:  270\n",
      "epoch:  271\n",
      "epoch:  272\n",
      "epoch:  273\n",
      "epoch:  274\n",
      "epoch:  275\n",
      "epoch:  276\n",
      "epoch:  277\n",
      "epoch:  278\n",
      "epoch:  279\n",
      "epoch:  280\n",
      "epoch:  281\n",
      "epoch:  282\n",
      "epoch:  283\n",
      "epoch:  284\n",
      "epoch:  285\n",
      "epoch:  286\n",
      "epoch:  287\n",
      "epoch:  288\n",
      "epoch:  289\n",
      "epoch:  290\n",
      "epoch:  291\n",
      "epoch:  292\n",
      "epoch:  293\n",
      "epoch:  294\n",
      "epoch:  295\n",
      "epoch:  296\n",
      "epoch:  297\n",
      "epoch:  298\n",
      "epoch:  299\n",
      "epoch:  300\n",
      "epoch:  301\n",
      "epoch:  302\n",
      "epoch:  303\n",
      "epoch:  304\n",
      "epoch:  305\n",
      "epoch:  306\n",
      "epoch:  307\n",
      "epoch:  308\n",
      "epoch:  309\n",
      "epoch:  310\n",
      "epoch:  311\n",
      "epoch:  312\n",
      "epoch:  313\n",
      "epoch:  314\n",
      "epoch:  315\n",
      "epoch:  316\n",
      "epoch:  317\n",
      "epoch:  318\n",
      "epoch:  319\n",
      "epoch:  320\n",
      "epoch:  321\n",
      "epoch:  322\n",
      "epoch:  323\n",
      "epoch:  324\n",
      "epoch:  325\n",
      "epoch:  326\n",
      "epoch:  327\n",
      "epoch:  328\n",
      "epoch:  329\n",
      "epoch:  330\n",
      "epoch:  331\n",
      "epoch:  332\n",
      "epoch:  333\n",
      "epoch:  334\n",
      "epoch:  335\n",
      "epoch:  336\n",
      "epoch:  337\n",
      "epoch:  338\n",
      "epoch:  339\n",
      "epoch:  340\n",
      "epoch:  341\n",
      "epoch:  342\n",
      "epoch:  343\n",
      "epoch:  344\n",
      "epoch:  345\n",
      "epoch:  346\n",
      "epoch:  347\n",
      "epoch:  348\n",
      "epoch:  349\n",
      "epoch:  350\n",
      "epoch:  351\n",
      "epoch:  352\n",
      "epoch:  353\n",
      "epoch:  354\n",
      "epoch:  355\n",
      "epoch:  356\n",
      "epoch:  357\n",
      "epoch:  358\n",
      "epoch:  359\n",
      "epoch:  360\n",
      "epoch:  361\n",
      "epoch:  362\n",
      "epoch:  363\n",
      "epoch:  364\n",
      "epoch:  365\n",
      "epoch:  366\n",
      "epoch:  367\n",
      "epoch:  368\n",
      "epoch:  369\n",
      "epoch:  370\n",
      "epoch:  371\n",
      "epoch:  372\n",
      "epoch:  373\n",
      "epoch:  374\n",
      "epoch:  375\n",
      "epoch:  376\n",
      "epoch:  377\n",
      "epoch:  378\n",
      "epoch:  379\n",
      "epoch:  380\n",
      "epoch:  381\n",
      "epoch:  382\n",
      "epoch:  383\n",
      "epoch:  384\n",
      "epoch:  385\n",
      "epoch:  386\n",
      "epoch:  387\n",
      "epoch:  388\n",
      "epoch:  389\n",
      "epoch:  390\n",
      "epoch:  391\n",
      "epoch:  392\n",
      "epoch:  393\n",
      "epoch:  394\n",
      "epoch:  395\n",
      "epoch:  396\n",
      "epoch:  397\n",
      "epoch:  398\n",
      "epoch:  399\n",
      "epoch:  400\n",
      "epoch:  401\n",
      "epoch:  402\n",
      "epoch:  403\n",
      "epoch:  404\n",
      "epoch:  405\n",
      "epoch:  406\n",
      "epoch:  407\n",
      "epoch:  408\n",
      "epoch:  409\n",
      "epoch:  410\n",
      "epoch:  411\n",
      "epoch:  412\n",
      "epoch:  413\n",
      "epoch:  414\n",
      "epoch:  415\n",
      "epoch:  416\n",
      "epoch:  417\n",
      "epoch:  418\n",
      "epoch:  419\n",
      "epoch:  420\n",
      "epoch:  421\n",
      "epoch:  422\n",
      "epoch:  423\n",
      "epoch:  424\n",
      "epoch:  425\n",
      "epoch:  426\n",
      "epoch:  427\n",
      "epoch:  428\n",
      "epoch:  429\n",
      "epoch:  430\n",
      "epoch:  431\n",
      "epoch:  432\n",
      "epoch:  433\n",
      "epoch:  434\n",
      "epoch:  435\n",
      "epoch:  436\n",
      "epoch:  437\n",
      "epoch:  438\n",
      "epoch:  439\n",
      "epoch:  440\n",
      "epoch:  441\n",
      "epoch:  442\n",
      "epoch:  443\n",
      "epoch:  444\n",
      "epoch:  445\n",
      "epoch:  446\n",
      "epoch:  447\n",
      "epoch:  448\n",
      "epoch:  449\n",
      "epoch:  450\n",
      "epoch:  451\n",
      "epoch:  452\n",
      "epoch:  453\n",
      "epoch:  454\n",
      "epoch:  455\n",
      "epoch:  456\n",
      "epoch:  457\n",
      "epoch:  458\n",
      "epoch:  459\n",
      "epoch:  460\n",
      "epoch:  461\n",
      "epoch:  462\n",
      "epoch:  463\n",
      "epoch:  464\n",
      "epoch:  465\n"
     ]
    }
   ],
   "source": [
    "# If you have matplotlib installed\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "def to_onehot(labels,nclasses = 5):\n",
    "    '''\n",
    "    Convert labels to \"one-hot\" format.\n",
    "    >>> a = [0,1,2,3]\n",
    "    >>> to_onehot(a,5)\n",
    "    array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "           [ 0.,  1.,  0.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  0.,  0.,  1.,  0.]])\n",
    "    '''\n",
    "    outlabels = np.zeros((len(labels),nclasses))\n",
    "    for i,l in enumerate(labels):\n",
    "        outlabels[i,l] = 1\n",
    "    return outlabels\n",
    "\n",
    "onehot = to_onehot(labels)\n",
    "\n",
    "# Split data into training and validation\n",
    "indices = np.random.permutation(train.shape[0])\n",
    "valid_cnt = int(train.shape[0] * 0.1)\n",
    "test_idx, training_idx = indices[:valid_cnt],\\\n",
    "                         indices[valid_cnt:]\n",
    "test, train = train[test_idx,:],\\\n",
    "              train[training_idx,:]\n",
    "onehot_test, onehot_train = onehot[test_idx,:],\\\n",
    "                        onehot[training_idx,:]\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# These will be inputs\n",
    "## Input pixels, image with one channel (gray)\n",
    "x = tf.placeholder(\"float\", [None, 36, 36])\n",
    "# Note that -1 is for reshaping\n",
    "x_im = tf.reshape(x, [-1,36,36,1])\n",
    "## Known labels\n",
    "# None works during variable creation to be\n",
    "# unspecified size\n",
    "y_ = tf.placeholder(\"float\", [None,5])\n",
    "\n",
    "# Conv layer 1\n",
    "num_filters1 = 16\n",
    "winx1 = 3\n",
    "winy1 = 3\n",
    "W1 = tf.Variable(tf.truncated_normal(\n",
    "    [winx1, winy1, 1 , num_filters1],\n",
    "    stddev=1./math.sqrt(winx1*winy1)))\n",
    "b1 = tf.Variable(tf.constant(0.1,\n",
    "                shape=[num_filters1]))\n",
    "# 5x5 convolution, pad with zeros on edges\n",
    "xw = tf.nn.conv2d(x_im, W1,\n",
    "                  strides=[1, 1, 1, 1],\n",
    "                  padding='SAME')\n",
    "h1 = tf.nn.relu(xw + b1)\n",
    "# 2x2 Max pooling, no padding on edges\n",
    "p1 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],\n",
    "        strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Conv layer 2\n",
    "num_filters2 = 4\n",
    "winx2 = 3\n",
    "winy2 = 3\n",
    "W2 = tf.Variable(tf.truncated_normal(\n",
    "    [winx2, winy2, num_filters1, num_filters2],\n",
    "    stddev=1./math.sqrt(winx2*winy2)))\n",
    "b2 = tf.Variable(tf.constant(0.1,\n",
    "     shape=[num_filters2]))\n",
    "# 3x3 convolution, pad with zeros on edges\n",
    "p1w2 = tf.nn.conv2d(p1, W2,\n",
    "       strides=[1, 1, 1, 1], padding='SAME')\n",
    "h1 = tf.nn.relu(p1w2 + b2)\n",
    "# 2x2 Max pooling, no padding on edges\n",
    "p2 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],\n",
    "     strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Need to flatten convolutional output\n",
    "p2_size = np.product(\n",
    "        [s.value for s in p2.get_shape()[1:]])\n",
    "p2f = tf.reshape(p2, [-1, p2_size ])\n",
    "\n",
    "# Dense layer\n",
    "num_hidden = 32\n",
    "W3 = tf.Variable(tf.truncated_normal(\n",
    "     [p2_size, num_hidden],\n",
    "     stddev=2./math.sqrt(p2_size)))\n",
    "b3 = tf.Variable(tf.constant(0.2,\n",
    "     shape=[num_hidden]))\n",
    "h3 = tf.nn.relu(tf.matmul(p2f,W3) + b3)\n",
    "\n",
    "# Drop out training\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h3_drop = tf.nn.dropout(h3, keep_prob)\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.truncated_normal(\n",
    "     [num_hidden, 5],\n",
    "     stddev=1./math.sqrt(num_hidden)))\n",
    "b4 = tf.Variable(tf.constant(0.1,shape=[5]))\n",
    "\n",
    "# Just initialize\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Define model\n",
    "y = tf.nn.softmax(tf.matmul(h3_drop,W4) + b4)\n",
    "\n",
    "### End model specification, begin training code\n",
    "\n",
    "\n",
    "# Climb on cross-entropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "        y + 1e-50, y_))\n",
    "\n",
    "# How we train\n",
    "train_step = tf.train.GradientDescentOptimizer(\n",
    "             0.01).minimize(cross_entropy)\n",
    "\n",
    "# Define accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),\n",
    "                              tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(\n",
    "           correct_prediction, \"float\"))\n",
    "\n",
    "# Actually train\n",
    "epochs = 1000\n",
    "train_acc = np.zeros(epochs/10)\n",
    "test_acc = np.zeros(epochs/10)\n",
    "for i in tqdm(range(epochs), ascii=True):\n",
    "    # Record summary data, and the accuracy\n",
    "    if i % 10 == 0:  \n",
    "        print 'epoch: ', i/10\n",
    "        # Check accuracy on train set\n",
    "        A = accuracy.eval(feed_dict={x: train,\n",
    "            y_: onehot_train, keep_prob: 1.0})\n",
    "        train_acc[i/10] = A\n",
    "        # And now the validation set\n",
    "        A = accuracy.eval(feed_dict={x: test,\n",
    "            y_: onehot_test, keep_prob: 1.0})\n",
    "        test_acc[i/10] = A\n",
    "    train_step.run(feed_dict={x: train,\\\n",
    "        y_: onehot_train, keep_prob: 0.5})\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(train_acc,'bo')\n",
    "plt.plot(test_acc,'rx')\n",
    "\n",
    "# Look at the final testing confusion matrix\n",
    "pred = np.argmax(y.eval(\n",
    "       feed_dict={x: test, keep_prob: 1.0,\n",
    "       y_: onehot_test}), axis = 1)\n",
    "conf = np.zeros([5,5])\n",
    "for p,t in zip(pred,np.argmax(onehot_test,\n",
    "                              axis=1)):\n",
    "    conf[t,p] += 1\n",
    "\n",
    "plt.matshow(conf)\n",
    "plt.colorbar()\n",
    "\n",
    "# Let's look at a subplot of some weights\n",
    "f, plts = plt.subplots(4,4)\n",
    "for i in range(16):\n",
    "    plts[i//4,i%4].matshow(W1.eval()[:,:,0,i],\n",
    "            cmap = plt.cm.gray_r)\n",
    "\n",
    "# Examine the output weights\n",
    "plt.matshow(W4.eval().T)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"conv2a.ckpt\")\n",
    "\n",
    "# Restore\n",
    "saver.restore(sess, \"conv2a.ckpt\")\n",
    "\n",
    "# Or use Numpy manually\n",
    "def save_all(name = 'conv2'):\n",
    "    np.savez_compressed(name, W1.eval(),\n",
    "            b1.eval(), W2.eval(), b2.eval(),\n",
    "            W3.eval(), b3.eval(), W4.eval(),\n",
    "            b4.eval())\n",
    "\n",
    "save_all()\n",
    "\n",
    "def load_all(name = 'conv2.npz'):\n",
    "    data = np.load(name)\n",
    "    sess.run(W1.assign(data['arr_0']))\n",
    "    sess.run(b1.assign(data['arr_1']))\n",
    "    sess.run(W2.assign(data['arr_2']))\n",
    "    sess.run(b2.assign(data['arr_3']))\n",
    "    sess.run(W3.assign(data['arr_4']))\n",
    "    sess.run(b3.assign(data['arr_5']))\n",
    "    sess.run(W4.assign(data['arr_6']))\n",
    "    sess.run(b4.assign(data['arr_7']))\n",
    "\n",
    "load_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
